% Script for the inverse source problem for the Poisson PDE using the PFNN architecture. The unknown source term is modeled %using a shallow neural network, which is trained by passing through the PFNN. Training uses MATLAB's LM algorithm.

%% Load the generated Poisson PDE outputs and corresponding grid points
% Assuming the generated outputs are saved in a MAT file
% along with the corresponding R_out and Theta_out grids as generated by the PFNN Poisson PDE script (use the sparse_sparse_prediction_for_inverse script).
% e.g., load('PFNN_Poisson_outputs.mat', 'u_train', 'R_out', 'Theta_out');

% Variables are assumed to be named: u_train, R_out, Theta_out - rename if necessary

%% Define the source term neural network architecture
N_neurons = 20;
source_net = feedforwardnet(N_neurons, 'trainlm');
source_net.layers{1}.transferFcn = 'tansig';
source_net.layers{2}.transferFcn = 'purelin';
% Configure the source term network with appropriate input and output sizes
source_net = configure(source_net, rand(2, 10), rand(1, 10));

%% Define the regularization parameter and other hyperparameters
lambda = 0.0; %1e-6;  % Regularization parameter

%% Define the error function for optimization
error_func = @(w) source_term_error(w, source_net, u_train, r_out, theta_out, lambda, phi_grid_dict, dphi, K, input_size, output_size, km_constant, phi);

% Extract the initial weights and biases from the source term network
initial_weights = getwb(source_net);

%% Set the optimization options
options = optimoptions('lsqnonlin', ...
    'Display', 'iter-detailed', ...
    'Algorithm', 'levenberg-marquardt', ...
    'FunctionTolerance', 1e-6, ...
    'MaxIterations', 500);

%% Perform the optimization using Levenberg-Marquardt
[optimal_weights, ~, ~, exitflag, output] = lsqnonlin(error_func, initial_weights, [], [], options);
source_net = setwb(source_net, optimal_weights);
save('trained_source_net.mat', 'source_net');

%% Evaluate the trained model
% Calculate the predicted outputs using the trained source term network
load('trained_source_net.mat', 'source_net');

disp('Evaluating the trained model...');

% Compute integral values using the trapezoidal rule
% integral_values = parallelIntegrateMeshgrid_net(r_out, theta_out, source_net);

r_src     = linspace(0,1,200);       % e.g. 60 integration radii
theta_src = linspace(0,2*pi,200);   % e.g. 128 integration angles
integral_values = trapezoidalIntegral(r_out, theta_out, source_net, r_src, theta_src);

% Extract the boundary integral values (r_out = 1)
precomputed_integrals_BIE = integral_values(end, :);

% Build lookup map for theta_out → integral
keys = num2cell(theta_out);
values = num2cell(precomputed_integrals_BIE);
precomputed_integral_map = containers.Map(keys, values);

% Instantiate the Fredholm model
fredholm_model = FredholmNeuralNetwork_PDE(...
    phi_grid_dict, ...          % grid dictionary
    @kernel, ...                % kernel handle
    dphi, ...                   % grid step
    K, ...                      % number of layers
    input_size, ...             % input size
    output_size, ...            % output size
    km_constant, ...            % km constant
    @funcFn, ...                % boundary function handle
    precomputed_integral_map ... % map of precomputed integrals
    );

% Instantiate the Limit-Informed model
limit_model = PotentialFredholmNeuralNetwork_Poisson(...
    fredholm_model, ...
    @diffPotentialsLimit, ...
    @potentialBoundary, ...
    integral_values, ...
    false);

% Perform the forward pass with the trained LINN model
u_pred = limit_model.forward(theta_out, r_out, theta_out, phi, dphi);

% Calculate the Mean Squared Error
mse_value = mean((u_pred(:) - u_train(:)).^2);
disp(['Final MSE: ', num2str(mse_value)]);


%% Visualize the results - Target Data
figure('Position', [100, 100, 600, 500]);
pcolor(Theta_out, R_out, u_train);
shading interp;
colorbar;
title('Target u\_train', 'FontSize', 14);
xlabel('\theta', 'FontSize', 12);
ylabel('r', 'FontSize', 12);

% Visualize the results - Predicted Data
figure('Position', [700, 100, 600, 500]);
pcolor(Theta_out, R_out, u_pred);
shading interp;
colorbar;
title('Predicted u\_pred', 'FontSize', 14);
xlabel('\theta', 'FontSize', 12);
ylabel('r', 'FontSize', 12);

% Visualize the results - Absolute Error
figure('Position', [100, 600, 600, 500]);
pcolor(Theta_out, R_out, abs(u_pred - u_train));
shading interp;
colorbar;
title('Absolute Error', 'FontSize', 14);
xlabel('\theta', 'FontSize', 12);
ylabel('r', 'FontSize', 12);

% Visualize the results - Learned Source Term
figure('Position', [700, 600, 600, 500]);
source_output = source_net([R_out(:), Theta_out(:)]');
source_grid = reshape(source_output, size(R_grid));
pcolor(Theta_out, R_out, source_grid);
shading interp;
colorbar;
title('Learned Source Term', 'FontSize', 14);
xlabel('\theta', 'FontSize', 12);
ylabel('r', 'FontSize', 12);

% 2) True source term on the full grid
% psi_true = 2 * R_out .* cos(Theta_out);
psi_true = (8*R_out + 24*R_out.^3).*sin(Theta_out);

% Visualize the results - Learned Source Term
figure('Position', [700, 600, 600, 500]);
pcolor(Theta_out, R_out, psi_true);
shading interp;
colorbar;
title('True Source Term', 'FontSize', 14);
xlabel('\theta', 'FontSize', 12);
ylabel('r', 'FontSize', 12);

% Print the final MSE again
fprintf('Final Mean Squared Error: %e\n', mse_value);

%% Error function for optimization
function error = source_term_error(weights, net, u_target, r_out, theta_out, lambda, phi_grid_dict, dphi, K, input_size, output_size, km_constant, phi)
    % Update the source term neural network weights
    net = setwb(net, weights);
    
    % Compute the integral values using the trapezoidal rule
    %fprintf('Starting integral at %s\n', datestr(now,'HH:MM:SS'));
    %tStart = tic;
    
    r_src     = linspace(0,1,200);       % e.g. 60 integration radii
    theta_src = linspace(0,2*pi,200);   % e.g. 128 integration angles
    integral_values = trapezoidalIntegral(r_out, theta_out, net, r_src, theta_src);

    % integral_values = trapezoidalIntegral(r_out, theta_out, net);
    % integral_values = parallelIntegrateMeshgrid_net(r_out, theta_out, net);

    %elapsed = toc(tStart);
    %fprintf('  → parallelIntegrateMeshgrid_net took %.3f s\n', elapsed);

    % Extract the boundary integral values (r_out = 1)
    precomputed_integrals_BIE = integral_values(end, :);
    
    % Build lookup map for theta_out → integral
    keys = num2cell(theta_out);
    values = num2cell(precomputed_integrals_BIE);
    
    precomputed_integral_map = containers.Map(keys, values);
    
    % Instantiate the updated Fredholm model
    fredholm_model = FredholmNeuralNetwork_PDE(...
        phi_grid_dict, ...                % grid dictionary
        @kernel, ...                      % kernel handle
        dphi, ...                         % grid step
        K, ...                            % number of layers
        input_size, ...                   % input size
        output_size, ...
        km_constant, ...                  % km constant
        @funcFn, ...                      % boundary function handle
        precomputed_integral_map ...      % map of precomputed integrals
        );
    
    % Instantiate the updated Limit-Informed model
    limit_model = LimitInformedNeuralNetwork_PDE(...
        fredholm_model, ...
        @diffPotentialsLimit, ...
        @potentialBoundary, ...
        integral_values, ...
        false);
    
    % Perform the forward pass with the updated LINN model
    u_pred = limit_model.forward(theta_out, r_out, theta_out, phi, dphi);
    
    % Compute the residuals (data error)
    err_data = u_pred(:) - u_target(:);
    
    % Compute the Tikhonov regularization term
    % source_output = net([r_out(:), theta_out(:)]'); %only works with same
    % dimensions 

    [Rg,Tg]       = ndgrid(r_out, theta_out);
    inputs        = [ Rg(:).'; Tg(:).' ];       % 2×(nr·nθ)
    source_output = net(inputs);                % 1×(nr·nθ)
    err_reg = sqrt(lambda) * source_output(:);

    % % Print their norms every time the function is called
    % fprintf('   ||data|| = %8.2e,   ||reg || = %8.2e\n', ...
    %         norm(err_data), norm(err_reg));
    
    % Concatenate the data error and regularization term
    error = [err_data; err_reg];
end

%% Integral using trapezoidal rule - fully vectorized

function integral_vals = parallelIntegrateMeshgrid_net(r_out_vals, theta_out_vals, source_net)
    tol = 1e-8;
    [R_out, Theta_out] = ndgrid(r_out_vals, theta_out_vals);
    Rf = R_out(:);
    Tf = Theta_out(:);
    results_flat = zeros(size(Rf));
    parfor i = 1:numel(Rf)
        results_flat(i) = integrateForOutValueScalar_net( ...
                             Rf(i), Tf(i), source_net, tol);
    end
    integral_vals = reshape(results_flat, size(R_out));
end

%------------------------------------------------
% 2) Outer integral over r2
function val = integrateForOutValueScalar_net(r_out, theta_out, source_net, tol)
    f_r2 = @(r2) innerIntegration_net(r2, r_out, theta_out, source_net, tol);
    val  = integral(f_r2, 0, 1, ...
                    'AbsTol',tol, 'RelTol',tol, ...
                    'Waypoints', r_out, ...
                    'ArrayValued', true);
end

%------------------------------------------------
% 3) Inner integral over theta
function inner = innerIntegration_net(r2, r_out, theta_out, source_net, tol)
    integrand_theta = @(th) fundamentalFn(r2, th, r_out, theta_out) ...
                         .* sourceTerm_net(r2, th, source_net);
    inner = integral(integrand_theta, 0, 2*pi, ...
                     'AbsTol',tol,'RelTol',tol, ...
                     'Waypoints', theta_out, ...
                     'ArrayValued', true);
end

%------------------------------------------------
% 4) Replace your old sourceTerm with this wrapper:
function src = sourceTerm_net(r2, th, source_net)
    % r2 is scalar, th is a vector
    %th = th(:).';                       % 1×N row
    %r2_row = r2 * ones(size(th));      % 1×N row
    % disp(size(th));
    % disp(size(r2_row));
    inputs = [r2; th];             % 2×N matrix
    src = source_net(inputs);          % 1×N row from the net
    src = reshape(src, size(th));      % keep it 1×N
    
end


function I_out = trapezoidalIntegral(...
        r_out, theta_out, source_net, r_src, theta_src)

    nr_out   = numel(r_out);
    ntheta_out = numel(theta_out);
    nr_src   = numel(r_src);
    ntheta_src = numel(theta_src);

    dr = r_src(2) - r_src(1);
    dth = theta_src(2) - theta_src(1);

    % Evaluate source_net once on the (r_src x theta_src) mesh
    [R_src, Th_src] = ndgrid(r_src, theta_src);
    S_in = [R_src(:).'; Th_src(:).'];
    psi_vals = source_net(S_in);             % 1 x (nr_src*ntheta_src)
    PSI = reshape(psi_vals, nr_src, ntheta_src);

    % Build 4-D broadcast arrays
    R1 = reshape(r_src,   [nr_src,1,1,1]);
    T1 = reshape(theta_src,[1,ntheta_src,1,1]);
    R2 = reshape(r_out,   [1,1,nr_out,1]);
    T2 = reshape(theta_out,[1,1,1,ntheta_out]);

    R_src_4D   = repmat(R1, [1,ntheta_src,nr_out,ntheta_out]);
    Th_src_4D  = repmat(T1, [nr_src,1,      nr_out,ntheta_out]);
    R_out_4D   = repmat(R2, [nr_src,ntheta_src,1,     ntheta_out]);
    Th_out_4D  = repmat(T2, [nr_src,ntheta_src,nr_out,1]);

    PSI_4D     = reshape(PSI, [nr_src,ntheta_src,1,1]);
    PSI_4D     = repmat(PSI_4D, [1,1,nr_out,ntheta_out]);

    DX = R_out_4D.*cos(Th_out_4D) - R_src_4D.*cos(Th_src_4D);
    DY = R_out_4D.*sin(Th_out_4D) - R_src_4D.*sin(Th_src_4D);
    R2dist = DX.^2 + DY.^2;
    R2dist(R2dist<1e-10) = 1e-10;

    FUND = (1/(2*pi)) * 0.5 * log(R2dist) .* R_src_4D;

    w_r = ones(nr_src,1);      w_r([1 end]) = 0.5;
    w_th= ones(1,ntheta_src);  w_th([1 end]) = 0.5;

    Wr   = reshape(w_r,  [nr_src,1,1,1]);
    Wth  = reshape(w_th, [1,ntheta_src,1,1]);
    W4   = Wr .* Wth;

    I_out = squeeze( sum(sum(FUND .* PSI_4D .* W4,1),2) ) * dr * dth;
end




%% Fundamental solution function
function fund = fundamentalFn(r, theta, r_out, theta_out)
    % Compute the 2D fundamental solution * r, vectorized in theta
    % Inputs: r (scalar), theta (scalar), r_out (scalar), theta_out (scalar)
    % Compute Cartesian differences correctly:
    dx = r_out.*cos(theta_out) - r.*cos(theta);
    dy = r_out.*sin(theta_out) - r.*sin(theta);

    R2 = dx.^2 + dy.^2;            % squared distance
    fund = (1/(2*pi)) * 0.5 * log(R2) .* r;
end

%% Kernel function
function k = kernel(inValue, outValue)
    weight = 1/(4*pi);
    k = -2 .* weight .* ones(size(inValue - outValue));
end

%% Function for funcFn
function out = funcFn(outValue)
    % out = zeros(size(outValue));
    out = 2*sin(outValue);
end

%% Potential and LINN functions
function kernelLimit = diffPotentialsLimit(phiIntegral, r_out, theta_out)
    % Ensure column vectors
    r   = r_out(:);
    th  = theta_out(:);
    ph  = phiIntegral(:);

    % Build 3-D grid (N×M×P)
    [R, TH, PH] = ndgrid(r, th, ph);

    % Boundary mask (where r_out == 1)
    mask = (R == 1.0);

    % Numerator & denominator of the integral kernel
    num = cos(PH) .* (cos(PH) - R .* cos(TH)) + ...
          sin(PH) .* (sin(PH) - R .* sin(TH));
    den = (cos(PH) - R .* cos(TH)).^2 + ...
          (sin(PH) - R .* sin(TH)).^2;

    Kmat = num ./ den;

    % Enforce the half-value on the boundary
    Kmat(mask) = 0.5;

    % Final "limit" kernel
    kernelLimit = (1 / (2*pi)) * (Kmat - 0.5);
end

function pb = potentialBoundary(phiIntegral, r_out, theta_out)
    % Ensure vectors
    r   = r_out(:);
    th  = theta_out(:);
    ph  = phiIntegral(:);

    % Build a dummy grid
    [R,~,~] = ndgrid(r, th, ph);

    % Constant value 1/(2π)*0.5 = 1/(4π)
    constantVal = 1 / (4*pi);

    % Fill entire 3-D array
    pb = constantVal * ones(size(R));
end


