# -*- coding: utf-8 -*-
"""Fredholm_NN_models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sNZF0EDiUbCn5pctzZX_j1qC19Ca9mAZ
"""

import torch
import torch.nn as nn
import numpy as np

class FredholmNeuralNetwork(nn.Module):
    def __init__(self, grid_dictionary, kernel, additive, grid_step, K, input_size, output_size):
        super(FredholmNeuralNetwork, self).__init__()

        self.grid_dictionary = grid_dictionary
        self.kernel = kernel
        self.additive = additive
        self.grid_step = grid_step
        self.K = K

        # Store dimensions for each layer
        self.layer_sizes = [input_size] + [len(grid_dictionary[f'layer_{i}']) for i in range(K + 1)]

    def compute_weights_and_biases(self):
        """Precomputes weights and biases based on the grid using vectorized operations."""
        weights = []
        biases = []

        for i in range(self.K + 1):
            if i == 0:
                # Boundary condition for the first layer
                mat = np.identity(self.layer_sizes[i])
                np.fill_diagonal(mat, self.additive(self.grid_dictionary[f'layer_{i}']))
                weights.append(torch.tensor(mat, dtype=torch.float32))
                biases.append(torch.zeros(self.layer_sizes[i], dtype=torch.float32))
            else:
                # Vectorized kernel computation for weight matrix
                grid_prev = np.expand_dims(self.grid_dictionary[f'layer_{i - 1}'], axis=1)  # [N, 1]
                grid_curr = np.expand_dims(self.grid_dictionary[f'layer_{i}'], axis=0)    # [1, M]

                weight_matrix = self.kernel(grid_prev, grid_curr) * self.grid_step  # [N, M]
                #print(weight_matrix)
                weights.append(torch.tensor(weight_matrix, dtype=torch.float32))

                # Compute biases for the current layer
                bias_vector = self.additive(self.grid_dictionary[f'layer_{i}'])
                biases.append(torch.tensor(bias_vector, dtype=torch.float32))

        return weights, biases

    def forward(self, predict_array):
        # Precompute weights and biases
        weights, biases = self.compute_weights_and_biases()

        # Pass input through the dynamically updated network
        x = torch.ones(len(self.grid_dictionary['layer_0']), dtype=torch.float32)
        for i in range(self.K + 1):
            x = torch.matmul(weights[i].T, x) + biases[i]

        # Compute the last hidden layer output
        nn_output = x

        grid = self.grid_dictionary[f'layer_{len(self.grid_dictionary) - 1}']

        # Final prediction based on predict_array
        weights_K_array = []
        predict_tensor = torch.tensor(predict_array, dtype=torch.float32)
        grid_tensor = torch.tensor(grid, dtype=torch.float32)

        for predict_value in predict_tensor:
            weights_K = torch.tensor([
                self.kernel(grid_value, predict_value.item()) * self.grid_step
                for grid_value in grid_tensor
            ], dtype=torch.float32).view(1, -1)
            weights_K_array.append(weights_K)

        weights_K_array = torch.cat(weights_K_array, dim=0)
        bias_K_array = self.additive(predict_tensor)

        prediction = torch.matmul(weights_K_array, nn_output.T) + bias_K_array

        return prediction.squeeze()

#KM implementation

import torch
import torch.nn as nn
import numpy as np
from scipy.stats import norm

class FredholmNeuralNetwork_KM(nn.Module):
    def __init__(self, grid_dictionary, kernel, additive, grid_step, K, input_size, output_size, km_constant):
        super(FredholmNeuralNetwork, self).__init__()

        self.grid_dictionary = grid_dictionary
        self.kernel = kernel
        self.additive = additive
        self.grid_step = grid_step
        self.K = K
        self.km_constant = km_constant

        # Store dimensions for each layer
        self.layer_sizes = [input_size] + [len(grid_dictionary[f'layer_{i}']) for i in range(K + 1)]

    def compute_weights_and_biases(self):
        """Precomputes weights and biases based on the grid using vectorized operations."""
        weights = []
        biases = []

        for i in range(self.K + 1):
            if i == 0:
                # Boundary condition for the first layer
                mat = np.identity(self.layer_sizes[i])
                np.fill_diagonal(mat, self.additive(self.grid_dictionary[f'layer_{i}']))
                weights.append(torch.tensor(mat, dtype=torch.float32))
                biases.append(torch.zeros(self.layer_sizes[i], dtype=torch.float32))
            else:
                # Vectorized kernel computation for weight matrix
                grid_prev = np.expand_dims(self.grid_dictionary[f'layer_{i - 1}'], axis=1)  # [N, 1]
                grid_curr = np.expand_dims(self.grid_dictionary[f'layer_{i}'], axis=0)    # [1, M]

                weight_matrix = (
                    self.kernel(grid_prev, grid_curr) * self.grid_step * self.km_constant +
                    (1 - self.km_constant) * ((grid_prev - grid_curr) == 0.0)

                )  # [N, M]
                weights.append(torch.tensor(weight_matrix, dtype=torch.float32))

                # Compute biases for the current layer
                bias_vector = self.additive(self.grid_dictionary[f'layer_{i}']) * self.km_constant
                biases.append(torch.tensor(bias_vector, dtype=torch.float32))

        return weights, biases

    def forward(self, predict_array):
        # Precompute weights and biases
        weights, biases = self.compute_weights_and_biases()

        # Pass input through the dynamically updated network
        x = torch.ones(len(self.grid_dictionary['layer_0']), dtype=torch.float32)
        for i in range(self.K + 1):
            x = torch.matmul(weights[i].T, x) + biases[i]

        # Compute the last hidden layer output
        nn_output = x
        print(nn_output)

        grid = self.grid_dictionary[f'layer_{len(self.grid_dictionary) - 1}']

        # Final prediction based on predict_array
        weights_K_array = []
        predict_tensor = torch.tensor(predict_array, dtype=torch.float32)
        grid_tensor = torch.tensor(grid, dtype=torch.float32)

        for predict_value in predict_tensor:
            weights_K = torch.tensor([
                self.kernel(grid_value, predict_value.item()) * self.grid_step
                for grid_value in grid_tensor
            ], dtype=torch.float32).view(1, -1)
            weights_K_array.append(weights_K)

        weights_K_array = torch.cat(weights_K_array, dim=0)
        bias_K_array = self.additive(predict_tensor)

        prediction = torch.matmul(weights_K_array, nn_output.T) + bias_K_array

        return prediction.squeeze()
